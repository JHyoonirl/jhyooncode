import cv2
import numpy as np
import argparse
import glob
import os
import sys
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from scipy.spatial.transform import Rotation as R


def load_camera_params(filename):
    """
    OpenCV FileStorage (YML/XML)ì—ì„œ ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ (ë‚´ë¶€ í–‰ë ¬ ë° ì™œê³¡ ê³„ìˆ˜)ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    camMatrix = np.array([])
    distCoeffs = np.array([])
    
    if not os.path.exists(filename):
        print(f"âŒ ì˜¤ë¥˜: ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ íŒŒì¼ '{filename}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return np.array([]), np.array([])

    fs = cv2.FileStorage(filename, cv2.FILE_STORAGE_READ)
    
    if fs.isOpened():
        # íŒŒì¼ì—ì„œ cameraMatrixì™€ distCoeffs ë…¸ë“œë¥¼ ì½ìŠµë‹ˆë‹¤.
        camMatrix = fs.getNode("cameraMatrix").mat()
        distCoeffs = fs.getNode("distCoeffs").mat()
        fs.release()
        
        if camMatrix is None or distCoeffs is None:
            print(f"ê²½ê³ : {filename} íŒŒì¼ì—ì„œ 'cameraMatrix' ë˜ëŠ” 'distCoeffs'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return np.array([]), np.array([])

        print(f"âœ… ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ ë¡œë“œ ì„±ê³µ: {filename}")
        return camMatrix, distCoeffs
    else:
        print(f"âŒ ì˜¤ë¥˜: ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ íŒŒì¼ {filename}ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return np.array([]), np.array([])
    

def load_images(pathname):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬(pathname)ì—ì„œ ëª¨ë“  .jpg ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ì—¬
    ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ì™€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not os.path.isdir(pathname):
        print(f"âŒ ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ '{pathname}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # glob.globì˜ ê²°ê³¼ë¥¼ ì •ë ¬í•˜ì—¬ ì´ë¯¸ì§€ ìˆœì„œë¥¼ ì¼ê´€ì„± ìˆê²Œ ìœ ì§€í•©ë‹ˆë‹¤.
    jpg_files = sorted(glob.glob(os.path.join(pathname, '*.jpg')))

    if not jpg_files:
        print(f"ğŸŸ¡ ì •ë³´: '{pathname}' ë””ë ‰í† ë¦¬ì—ì„œ JPG ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return [], []

    images = []
    image_paths = [] # ğŸ’¡ íŒŒì¼ ê²½ë¡œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
    
    for img_path in jpg_files:
        img = cv2.imread(img_path)
        if img is not None:
            images.append(img)
            image_paths.append(img_path) # ğŸ’¡ ë¦¬ìŠ¤íŠ¸ì— ê²½ë¡œ ì¶”ê°€
        else:
            print(f"âš ï¸ ê²½ê³ : '{img_path}' íŒŒì¼ì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    print(f"âœ… ì´ë¯¸ì§€ ë¡œë“œ ì„±ê³µ: ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return images, image_paths # ğŸ’¡ ì´ë¯¸ì§€ì™€ ê²½ë¡œë¥¼ í•¨ê»˜ ë°˜í™˜
    
def map_generator(camMatrix, distCoeffs, image_size):
    """
    ì£¼ì–´ì§„ ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ë¡œ ì™œê³¡ ë³´ì • ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    new_camMatrix, roi = cv2.getOptimalNewCameraMatrix(
        camMatrix, distCoeffs, image_size, 0, image_size
    )

    mapx, mapy = cv2.initUndistortRectifyMap(
        camMatrix, distCoeffs, None, new_camMatrix, image_size, cv2.CV_32FC1
    )
    
    return mapx, mapy



def initialize_aruco_detector(dictionary_type=cv2.aruco.DICT_6X6_250):
    """
    ArUco ê²€ì¶œì„ ìœ„í•œ ì‚¬ì „(dictionary)ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    
    Args:
        dictionary_type: ì‚¬ìš©í•  ArUco ë”•ì…”ë„ˆë¦¬ íƒ€ì….
        
    Returns:
        ArUco ë”•ì…”ë„ˆë¦¬ ê°ì²´, ê²€ì¶œê¸° íŒŒë¼ë¯¸í„° ê°ì²´.
    """
    print(f"âœ… ArUco ê²€ì¶œê¸° ì´ˆê¸°í™” (ì‚¬ì „: {dictionary_type})")
    aruco_dict = cv2.aruco.getPredefinedDictionary(dictionary_type)
    aruco_params = cv2.aruco.DetectorParameters()
    aruco_params.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX 
    
    # 3. ì‚¬ì „ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 'íƒì§€ê¸°' ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
    
    return detector

def detect_and_draw_aruco(image, cam_matrix, dist_coeffs, detector: cv2.aruco.ArucoDetector, marker_length=0.1):
    """
    í•œ ì´ë¯¸ì§€ ë‚´ì—ì„œ ArUco ë§ˆì»¤ë¥¼ ê²€ì¶œí•˜ê³ , Poseë¥¼ ì¶”ì •í•˜ì—¬ ì¶•ì„ ê·¸ë¦½ë‹ˆë‹¤.
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€.
        cam_matrix: ì¹´ë©”ë¼ ë‚´ë¶€ í–‰ë ¬.
        dist_coeffs: ì¹´ë©”ë¼ ì™œê³¡ ê³„ìˆ˜.
        aruco_dict: ArUco ë”•ì…”ë„ˆë¦¬.
        aruco_params: ArUco ê²€ì¶œê¸° íŒŒë¼ë¯¸í„°.
        marker_length: ì‹¤ì œ ë§ˆì»¤ì˜ í•œ ë³€ ê¸¸ì´ (ë¯¸í„° ë‹¨ìœ„).
        
    Returns:
        ë§ˆì»¤ ì •ë³´ê°€ ê·¸ë ¤ì§„ ê²°ê³¼ ì´ë¯¸ì§€, íšŒì „ ë²¡í„° ë¦¬ìŠ¤íŠ¸, ì´ë™ ë²¡í„° ë¦¬ìŠ¤íŠ¸.
    """
    # 1. ì´ë¯¸ì§€ ì™œê³¡ ë³´ì •
    undistorted_img = cv2.undistort(image, cam_matrix, dist_coeffs)
    
    # âœ¨ detector ê°ì²´ì˜ detectMarkers ë©”ì„œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    corners, ids, rejected = detector.detectMarkers(undistorted_img)
    
    rvecs, tvecs = None, None
    if ids is not None:
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
            corners, marker_length, cam_matrix, dist_coeffs
        )
        cv2.aruco.drawDetectedMarkers(undistorted_img, corners, ids)
        for rvec, tvec in zip(rvecs, tvecs):
            if hasattr(cv2, 'drawFrameAxes'):
                cv2.drawFrameAxes(undistorted_img, cam_matrix, dist_coeffs, rvec, tvec, marker_length / 2)
            else:
                cv2.aruco.drawAxis(undistorted_img, cam_matrix, dist_coeffs, rvec, tvec, marker_length / 2)
                
    return undistorted_img, rvecs, tvecs

def process_camera_images(camera_name, images, paths, cam_matrix, dist_coeffs, aruco_detector, marker_length, save_dir_base):
    """
    ì§€ì •ëœ ì¹´ë©”ë¼ì˜ ì´ë¯¸ì§€ ì„¸íŠ¸ì— ëŒ€í•´ ArUco ê²€ì¶œ ë° ì €ì¥ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    if not images:
        print(f"ğŸŸ¡ {camera_name} ì¹´ë©”ë¼ ì´ë¯¸ì§€ê°€ ì—†ì–´ ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    # ì¹´ë©”ë¼ë³„ ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
    save_dir_specific = os.path.join(save_dir_base, camera_name)
    os.makedirs(save_dir_specific, exist_ok=True)
    print(f"\nâ–¶ï¸  '{camera_name}' ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘... (ê²°ê³¼ ì €ì¥: '{save_dir_specific}')")

    for img, path in zip(images, paths):
        filename = os.path.basename(path)
        
        # ArUco ë§ˆì»¤ ê²€ì¶œ ë° ê·¸ë¦¬ê¸°
        result_img, rvecs, tvecs = detect_and_draw_aruco(
            img, cam_matrix, dist_coeffs, aruco_detector, marker_length
        )
        
        if rvecs is not None:
            print(f"  âœ… [{filename}] ë§ˆì»¤ ê²€ì¶œ ì™„ë£Œ.")
        else:
            print(f"  ğŸŸ¡ [{filename}] ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # ê²°ê³¼ ì €ì¥ ë° í™”ë©´ ì¶œë ¥
        save_path = os.path.join(save_dir_specific, filename)
        cv2.imwrite(save_path, result_img)
        cv2.imshow(f"{camera_name} - ArUco Result", result_img)

        if cv2.waitKey(250) & 0xFF == ord('q'): # 0.25ì´ˆ ëŒ€ê¸°
            print("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return True # ì¤‘ë‹¨ ì‹ í˜¸ ë°˜í™˜
    return False # ì •ìƒ ì¢…ë£Œ

def calculate_average_marker_pose(images, cam_matrix, dist_coeffs, detector: cv2.aruco.ArucoDetector, marker_length):
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ì—ì„œ ArUco ë§ˆì»¤ì˜ Poseë¥¼ ê²€ì¶œí•˜ê³  í‰ê·  íšŒì „ ë° ì´ë™ ë²¡í„°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    all_rotations = []
    all_translations = []

    print(f"--- ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€ì—ì„œ í‰ê·  Pose ê³„ì‚° ì‹œì‘ ---")
    
    for i, image in enumerate(images):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        corners, ids, _ = detector.detectMarkers(gray)

        if ids is not None and len(ids) == 1:
            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_length, cam_matrix, dist_coeffs)
            rotation_matrix, _ = cv2.Rodrigues(rvecs[0])
            all_rotations.append(rotation_matrix)
            all_translations.append(tvecs[0])
            print(f"  [{i+1}/{len(images)}] âœ… ë§ˆì»¤ ê²€ì¶œ ì„±ê³µ")
        else:
            print(f"  [{i+1}/{len(images)}] ğŸŸ¡ ë§ˆì»¤ ê²€ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ì—¬ëŸ¬ ê°œ ê²€ì¶œë¨")

    if not all_rotations:
        return None, None

    avg_translation = np.mean(all_translations, axis=0)
    print(f"  âœ… í‰ê·  Translation: {avg_translation}")
    avg_rotation_matrix = R.from_matrix(all_rotations).mean().as_matrix()
    print(f"  âœ… í‰ê·  Rotation: {avg_rotation_matrix}")

    print(f"--- {len(all_rotations)}ê°œì˜ ìœ íš¨ ë°ì´í„°ë¡œ í‰ê·  Pose ê³„ì‚° ì™„ë£Œ ---")
    return avg_rotation_matrix, avg_translation

def draw_axis(ax, R, t, label, length=0.1):
    """3D í”Œë¡¯ì— ì¢Œí‘œê³„ë¥¼ ê·¸ë¦¬ëŠ” í—¬í¼ í•¨ìˆ˜"""
    origin = t.flatten()
    
    # ê° ì¶•ì˜ ë°©í–¥ ë²¡í„° (X:Red, Y:Green, Z:Blue)
    x_axis = R[:, 0]
    y_axis = R[:, 1]
    z_axis = R[:, 2]
    
    # Quiverë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ì‚´í‘œ(ì¶•) ê·¸ë¦¬ê¸°
    ax.quiver(origin[0], origin[1], origin[2], x_axis[0], x_axis[1], x_axis[2], length=length, color='r', normalize=True)
    ax.quiver(origin[0], origin[1], origin[2], y_axis[0], y_axis[1], y_axis[2], length=length, color='g', normalize=True)
    ax.quiver(origin[0], origin[1], origin[2], z_axis[0], z_axis[1], z_axis[2], length=length, color='b', normalize=True)
    
    # ì¢Œí‘œê³„ ì´ë¦„ í‘œì‹œ
    ax.text(origin[0], origin[1], origin[2], f'  {label}', color='k')



if __name__ == "__main__": 
    
    realsense_camMatrix, realsense_distCoeffs = load_camera_params("param/realsense_camera_params.yml")
    unitree_camMatrix, unitree_distCoeffs = load_camera_params("param/unitree_camera_params.yml")

    if np.size(realsense_camMatrix) == 0 or np.size(unitree_camMatrix) == 0:
        print("\nâŒ ì˜¤ë¥˜: ìœ íš¨í•œ ì¹´ë©”ë¼ ë§¤ê°œë³€ìˆ˜ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ë™ì˜ìƒì„ ë³´ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # realsense_mapx, realsense_mapy = map_generator(
    #     realsense_camMatrix, realsense_distCoeffs, (1280, 720)
    # )

    # unitree_mapx, unitree_mapy = map_generator(
    #     unitree_camMatrix, unitree_distCoeffs, (1280, 720)
    # )

    realsense_images, realsense_paths = load_images("images/realsense")
    unitree_images, unitree_paths = load_images("images/unitree")

    aruco_detector = initialize_aruco_detector()
    MARKER_LENGTH_M = 0.1  # ë§ˆì»¤ í•œ ë³€ì˜ ì‹¤ì œ ê¸¸ì´ (5cm)
    SAVE_DIRECTORY_BASE = "aruco_results"

    
    print("\n[ë‹¨ê³„ 1/2] Realsense ì¹´ë©”ë¼ì˜ í‰ê·  Poseë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
    R_realsense_to_marker, t_realsense_to_marker = calculate_average_marker_pose(
        realsense_images, realsense_camMatrix, realsense_distCoeffs, aruco_detector, MARKER_LENGTH_M
    )

    print("\n[ë‹¨ê³„ 2/2] Unitree ì¹´ë©”ë¼ì˜ í‰ê·  Poseë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.")
    R_unitree_to_marker, t_unitree_to_marker = calculate_average_marker_pose(
        unitree_images, unitree_camMatrix, unitree_distCoeffs, aruco_detector, MARKER_LENGTH_M
    )
    
    if R_realsense_to_marker is None or R_unitree_to_marker is None:
        print("\nâŒ ì˜¤ë¥˜: í•œ ì¹´ë©”ë¼ë¼ë„ ìœ íš¨í•œ ë§ˆì»¤ Poseë¥¼ ê³„ì‚°í•˜ì§€ ëª»í•´ 3D ì‹œê°í™”ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # 1. ê° ë³€í™˜ì„ 4x4 ë™ì°¨ í–‰ë ¬ë¡œ ë§Œë“­ë‹ˆë‹¤.
    # T(marker <- unitree): Unitreeì—ì„œ Markerë¡œì˜ ë³€í™˜
    T_marker_from_unitree = np.eye(4)
    T_marker_from_unitree[:3, :3] = R_unitree_to_marker
    T_marker_from_unitree[:3, 3] = t_unitree_to_marker.flatten()

    # T(marker <- realsense): Realsenseì—ì„œ Markerë¡œì˜ ë³€í™˜
    T_marker_from_realsense = np.eye(4)
    T_marker_from_realsense[:3, :3] = R_realsense_to_marker
    T_marker_from_realsense[:3, 3] = t_realsense_to_marker.flatten()

    # 2. í•„ìš”í•œ ì—­í–‰ë ¬ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    # T(unitree <- marker) = T(marker <- unitree)ì˜ ì—­í–‰ë ¬
    T_unitree_from_marker = np.linalg.inv(T_marker_from_unitree)

    # 3. ë³€í™˜ì„ ìˆœì„œëŒ€ë¡œ ê³±í•©ë‹ˆë‹¤: T(unitree -> realsense) = T(unitree -> marker) @ T(marker -> realsense)
    # T(unitree -> realsense)ëŠ” T(realsense <- unitree)ì™€ ê°™ìŠµë‹ˆë‹¤.
    T_realsense_from_unitree = np.linalg.inv(T_marker_from_realsense @ T_unitree_from_marker)

    # 4. 4x4 í–‰ë ¬ì—ì„œ ìµœì¢… íšŒì „(R)ê³¼ ì´ë™(t)ì„ ë‹¤ì‹œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    R_unitree_to_realsense = T_realsense_from_unitree[:3, :3]
    t_unitree_to_realsense = T_realsense_from_unitree[:3, 3]
    print(f"\nâœ… Unitree -> Realsense íšŒì „ í–‰ë ¬:\n{R_unitree_to_realsense}")
    print(f"\nâœ… Unitree -> Realsense ì´ë™ ë²¡í„°:\n{t_unitree_to_realsense}")
    # === 3D í”Œë¡¯ ìƒì„± ===

    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')

    # 1. Realsense ì¹´ë©”ë¼ ì¢Œí‘œê³„ ê·¸ë¦¬ê¸° (ì›”ë“œ ì›ì )
    R_world = np.identity(3)
    t_world = np.array([[0], [0], [0]])
    draw_axis(ax, R_world, t_world, "world(unitree)")
    draw_axis(ax, R_unitree_to_realsense, t_unitree_to_realsense, "realsense cam")

    # 2. ArUco ë§ˆì»¤ ì¢Œí‘œê³„ ê·¸ë¦¬ê¸° (Realsense ê¸°ì¤€)
    draw_axis(ax, R_unitree_to_marker, t_unitree_to_marker, "ArUco Marker_from_unitree")
    # draw_axis(ax, R_realsense_to_marker, t_realsense_to_marker, "ArUco Marker_from_realsense")

    # 3. Unitree ì¹´ë©”ë¼ ì¢Œí‘œê³„ ê·¸ë¦¬ê¸° (Realsense ê¸°ì¤€)
    # draw_axis(ax, R_unitree_to_realsense, t_unitree_to_realsense, "Unitree Cam")

    # í”Œë¡¯ ì„¤ì •
    ax.set_xlabel("X (m)")
    ax.set_ylabel("Y (m)")
    ax.set_zlabel("Z (m)")
    ax.set_title("3D Visualization of Camera and Marker Poses")
    ax.grid(True)

    # ê° ì¶•ì˜ ìŠ¤ì¼€ì¼ì„ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì—¬ ì™œê³¡ ë°©ì§€
    max_range = 1
    ax.set_xlim(-max_range, max_range)
    ax.set_ylim(-max_range, max_range)
    ax.set_zlim(-max_range, max_range)
    ax.set_box_aspect([1,1,1]) # ì¶• ë¹„ìœ¨ì„ 1:1:1ë¡œ ì„¤ì •

    ax.view_init(elev=-90, azim=270)

    plt.show()

    # print("\nâœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    # cv2.destroyAllWindows()

    # print("\nâœ… ëª¨ë“  ì´ë¯¸ì§€ì˜ ì™œê³¡ ë³´ì • ë° ì €ì¥ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    # cv2.destroyAllWindows() # ëª¨ë“  ì°½ ë‹«ê¸°
